defaults:
  - pipeline
  - stage_configs:
      - shard_events
      - split_and_shard_patients
      - merge_to_MEDS_cohort
      - extract_code_metadata
      - finalize_MEDS_metadata
      # There is no configuration beyond the global "event_conversion_config_fp" for the
      # convert_to_sharded_events stage, so it doesn't have a stage config block here or below.
  - _self_

etl_metadata.pipeline_name: "extract"

description: |-
  This pipeline extracts raw MEDS events in longitudinal, sparse form from an input dataset meeting select
  criteria and converts them to the flattened, MEDS format. It can be run in its entirety, with controllable
  levels of parallelism, or in stages. Arguments:
    - `event_conversion_config_fp`: The path to the event conversion configuration file. This file defines
      the events to extract from the various rows of the various input files encountered in the global input
      directory.
    - `input_dir`: The path to the directory containing the raw input files.
    - `cohort_dir`: The path to the directory where the output cohort will be written. It will be written in
      various subfolders of this dir depending on the stage, as intermediate stages cache their output during
      computation for efficiency of re-running and distributing.

# The event conversion configuration file is used throughout the pipeline to define the events to extract.
event_conversion_config_fp: ???
# The code modifier columns are in this pipeline only used in the aggregate_code_metadata stage.
code_modifiers: null
# The shards mapping is stored in the root of the final output directory.
shards_map_fp: "${cohort_dir}/splits.json"

stages:
  - shard_events
  - split_and_shard_patients
  - convert_to_sharded_events
  - merge_to_MEDS_cohort
  - aggregate_code_metadata
  - extract_code_metadata
  - finalize_MEDS_metadata

stage_configs:
  shard_events:
    data_input_dir: "${input_dir}"
  aggregate_code_metadata:
    description: |-
      This stage collects some descriptive metadata about the codes in the cohort.

      Args:
        stage_cfg.aggregations: The aggregations to compute over the codes.
          Defaults to counts of code occurrences, counts of patients with the code, and counts of value
          occurrences per code, as well as the sum and sum of squares of values (for use in computing means
          and variances).
    aggregations:
      - "code/n_occurrences"
      - "code/n_patients"
      - "values/n_occurrences"
      - "values/sum"
      - "values/sum_sqd"
    do_summarize_over_all_codes: true # This indicates we should include overall, code-independent counts
    process_shard_prefix: "train/" # we only want to summarize over the training set
