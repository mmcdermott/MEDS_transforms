defaults:
  - pipeline
  - stage_configs:
      - shard_events
      - split_and_shard_patients
      - merge_to_MEDS_cohort
  - _self_

description: |-
  This pipeline extracts raw MEDS events in longitudinal, sparse form from an input dataset meeting select
  criteria and converts them to the flattened, MEDS format. It can be run in its entirety, with controllable
  levels of parallelism, or in stages. Arguments:
    - `event_conversion_config_fp`: The path to the event conversion configuration file. This file defines
      the events to extract from the various rows of the various input files encountered in the global input
      directory.
    - `input_dir`: The path to the directory containing the raw input files.
    - `cohort_dir`: The path to the directory where the output cohort will be written. It will be written in
      various subfolders of this dir depending on the stage, as intermediate stages cache their output during
      computation for efficiency of re-running and distributing.

# The event conversion configuration file is used throughout the pipeline to define the events to extract.
event_conversion_config_fp: ???
# The code modifier columns are in this pipeline only used in the aggregate_code_metadata stage.
code_modifiers: null
# The shards mapping is stored in the root of the final output directory.
shards_map_fp: "${cohort_dir}/splits.json"

stages:
  - shard_events
  - split_and_shard_patients
  - convert_to_sharded_events
  - merge_to_MEDS_cohort
  - aggregate_code_metadata

stage_configs:
  aggregate_code_metadata:
    description: |-
      This stage collects some descriptive metadata about the codes in the cohort. Arguments:
        - `aggregations`: The aggregations to compute over the codes. Defaults to counts of code occurrences,
          counts of patients with the code, and counts of value occurrences per code, as well as the sum and
          sum of squares of values (for use in computing means and variances).
    aggregations:
      - "code/n_occurrences"
      - "code/n_patients"
      - "values/n_occurrences"
      - "values/sum"
      - "values/sum_sqd"
    do_summarize_over_all_codes: true # This indicates we should include overall, code-independent counts
    is_metadata: True
    mapper_output_dir: "${cohort_dir}/code_metadata"
    output_dir: "${cohort_dir}"
    process_shard_prefix: "train/" # we only want to summarize over the training set
