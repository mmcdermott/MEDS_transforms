"""Utilities for sharding/re-sharding and splitting MEDS datasets."""

from collections.abc import Sequence

import numpy as np
from loguru import logger


def shard_patients[
    SUBJ_ID_T
](
    patients: np.ndarray,
    n_patients_per_shard: int = 50000,
    external_splits: dict[str, Sequence[SUBJ_ID_T]] | None = None,
    split_fracs_dict: dict[str, float] = {"train": 0.8, "tuning": 0.1, "held_out": 0.1},
    seed: int = 1,
) -> dict[str, list[SUBJ_ID_T]]:
    """Shard a list of patients, nested within train/tuning/held-out splits.

    This function takes a list of patients and shards them into train/tuning/held-out splits, with the shards
    of a consistent size, nested within the splits. The function will also respect external splits, if
    provided, such that mandated splits (such as prospective held out sets or pre-existing, task-specific held
    out sets) are with-held and sharded as separate splits from the IID splits defined by `split_fracs_dict`.
    It returns a dictionary mapping the split and shard names (realized as f"{split}/{shard}") to the list of
    patients in that shard.

    Args:
        patients: The list of patients to shard.
        n_patients_per_shard: The maximum number of patients to include in each shard.
        external_splits: The externally defined splits to respect. If provided, the keys of this dictionary
            will be used as split names, and the values as the list of patients in that split. These
            pre-defined splits will be excluded from IID splits generated by this function, but will be
            sharded like normal. Note that this is largely only appropriate for held-out sets for pre-defined
            tasks or test cases (e.g., prospective tests); training patients should often still be included in
            the IID splits to maximize the amount of data that can be used for training.
        split_fracs_dict: A dictionary mapping the split name to the fraction of patients to include in that
            split. Defaults to 80% train, 10% tuning, 10% held-out.
        seed: The random seed to use for shuffling the patients before seeding and sharding. This is useful
            for ensuring reproducibility.

    Returns:
        A dictionary mapping f"{split}/{shard}" to the list of patients in that shard. This may include
        overlapping patients across a subset of these splits, but never across shards within a split. Any
        overlap will solely occur between the an external split and another external split.

    Raises:
        ValueError: If the sum of the split fractions in `split_fracs_dict` is not equal to 1.

    Examples:
        >>> patients = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=int)
        >>> shard_patients(patients, n_patients_per_shard=3)
        {'train/0': [9, 4, 8], 'train/1': [2, 1, 10], 'train/2': [6, 5], 'tuning/0': [3], 'held_out/0': [7]}
        >>> external_splits = {
        ...     'taskA/held_out': np.array([8, 9, 10], dtype=int),
        ...     'taskB/held_out': np.array([10, 8, 9], dtype=int),
        ... }
        >>> shard_patients(patients, 3, external_splits) # doctest: +NORMALIZE_WHITESPACE
        {'train/0': [5, 7, 4],
         'train/1': [1, 2],
         'tuning/0': [3],
         'held_out/0': [6],
         'taskA/held_out/0': [8, 9, 10],
         'taskB/held_out/0': [10, 8, 9]}
        >>> shard_patients(patients, n_patients_per_shard=3, split_fracs_dict={'train': 0.5})
        Traceback (most recent call last):
            ...
        ValueError: The sum of the split fractions must be equal to 1.
        >>> shard_patients([1, 2], n_patients_per_shard=3)
        Traceback (most recent call last):
            ...
        ValueError: Unable to adjust splits to ensure all splits have at least 1 patient.
    """

    if sum(split_fracs_dict.values()) != 1:
        raise ValueError("The sum of the split fractions must be equal to 1.")

    if external_splits is None:
        external_splits = {}
    else:
        for k in list(external_splits.keys()):
            if not isinstance(external_splits[k], np.ndarray):
                logger.warning(
                    f"External split {k} is not a numpy array and thus type safety is not guaranteed. "
                    f"Attempting to convert to numpy array of dtype {patients.dtype}."
                )
                external_splits[k] = np.array(external_splits[k], dtype=patients.dtype)

    patients = np.unique(patients)

    # Splitting
    all_external_splits = set().union(*external_splits.values())
    is_in_external_split = np.isin(patients, list(all_external_splits))
    patient_ids_to_split = patients[~is_in_external_split]

    n_patients = len(patient_ids_to_split)

    rng = np.random.default_rng(seed)
    split_names_idx = rng.permutation(len(split_fracs_dict))
    split_names = np.array(list(split_fracs_dict.keys()))[split_names_idx]
    split_fracs = np.array([split_fracs_dict[k] for k in split_names])
    split_lens = np.round(split_fracs[:-1] * n_patients).astype(int)
    split_lens = np.append(split_lens, n_patients - split_lens.sum())

    if split_lens.min() == 0:
        logger.warning(
            "Some splits are empty. Adjusting splits to ensure all splits have at least 1 patient."
        )
        max_split = split_lens.argmax()
        split_lens[max_split] -= 1
        split_lens[split_lens.argmin()] += 1

    if split_lens.min() == 0:
        raise ValueError("Unable to adjust splits to ensure all splits have at least 1 patient.")

    patients = rng.permutation(patient_ids_to_split)
    patients_per_split = np.split(patients, split_lens.cumsum())

    splits = {k: v for k, v in zip(split_names, patients_per_split)}
    splits = {**splits, **external_splits}

    # Sharding
    final_shards = {}
    for sp, pts in splits.items():
        if len(pts) <= n_patients_per_shard:
            final_shards[f"{sp}/0"] = pts.tolist()
        else:
            pts = rng.permutation(pts)
            n_pts = len(pts)
            n_shards = int(np.ceil(n_pts / n_patients_per_shard))
            shards = np.array_split(pts, n_shards)
            for i, shard in enumerate(shards):
                final_shards[f"{sp}/{i}"] = shard.tolist()

    seen = {}

    for k, pts in final_shards.items():
        logger.info(f"Split {k} has {len(pts)} patients.")

        for kk, v in seen.items():
            shared = set(pts).intersection(v)
            if shared:
                logger.info(f"  - intersects {kk} on {len(shared)} patients.")

        seen[k] = set(pts)

    return final_shards
